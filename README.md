**README: AgiHouse Hackathon - Putin Persona Simulation (RAG Implementation)**

**Project Goal:**

This project explores the potential of using Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) to simulate the strategic thinking and decision-making processes of world leaders, specifically focusing on Vladimir Putin. The objective is to create an AI-driven chatbot persona that models Putin's *inferred private rationale and unfiltered thoughts*, distinct from his public statements, to better understand potential future actions and strategic intentions of the Russian Federation.

**Architecture Overview:**

This project implements a Retrieval-Augmented Generation (RAG) system:

1.  **Data Ingestion:** Text documents (speeches, articles, etc.) and associated metadata are processed, chunked, and embedded using Voyage AI.
2.  **Storage:** File metadata, text chunks, and their vector embeddings are stored in a Supabase PostgreSQL database (likely utilizing pgvector).
3.  **Query Processing:** When a user sends a message:
    * The query is embedded using Voyage AI.
    * Supabase is queried to find semantically similar text chunks based on vector similarity.
    * The retrieved chunks are reranked for relevance to the specific query using Voyage AI's reranking API.
4.  **LLM Interaction:** The top reranked chunks are passed as context, along with the user's message and a detailed system prompt defining the "Unfiltered Putin" persona, to OpenAI's GPT-4o model via the BAML framework.
5.  **Response Streaming:** The response generated by GPT-4o is streamed back to the user interface using Server-Sent Events (SSE).

**Methodology:**

1.  **Data Aggregation & Processing:**
    * We gathered diverse data sources (as described previously: primary, Russian, Western, etc.).
    * Scripts (`scripts/process_data.ts`, `scripts/to_txt.ts`) process local text files and associated metadata files.
    * Text content is chunked into manageable segments (`services/supabase.ts`).
    * **Voyage AI** (`services/voyage.ts`) is used to generate vector embeddings for these text chunks (`voyage-3` model noted in batch processing).
    * Processed data (file metadata, chunks, embeddings) is stored in **Supabase** (`services/supabase.ts`).

2.  **Retrieval & Reranking:**
    * User queries are embedded using **Voyage AI** (`voyage-01` query model noted).
    * A custom Supabase RPC function (`query_embeddings`) performs vector similarity search (`services/query.ts`).
    * Retrieved results are reranked for contextual relevance using **Voyage AI's reranking model** (`rerank-2` model noted) to select the best context for the LLM (`services/voyage.ts`, `services/query.ts`).

3.  **Persona Modeling & Generation:**
    * **BAML (`@boundaryml/baml`)** is used to manage LLM interactions, define prompt structures, and generate typed clients (`baml_client/`, `baml_src/`).
    * The core "Unfiltered Putin" system prompt is explicitly defined within `baml_src/chat.baml`, instructing the AI on persona, tone, and worldview.
    * The BAML `Chat` function integrates the user message, the reranked context (`rerankedResults`), and the system prompt.
    * **OpenAI's GPT-4o** is configured as the underlying LLM (`baml_src/clients.baml`).

4.  **API & Interface:**
    * An **Express.js** server (`server.ts`) written in **TypeScript** handles API requests.
    * The `/chat` endpoint orchestrates the RAG process (search, rerank, LLM call) and streams the response back to the client via Server-Sent Events (SSE).
    * An optional `/transcribe` endpoint utilizes **OpenAI Whisper** (`services/transcription-service.ts`) for potential audio input.
    * A static frontend (`public/`) provides the user interface.

**Hypothesis & Potential Applications:**

(This section remains largely the same as before, emphasizing RAG's contribution)

Our hypothesis is that by simulating a leader's inferred private reasoning, augmented by relevant retrieved context using RAG, AI can serve as a valuable tool for geopolitical analysis and prediction.

* **Enhanced Understanding:** This approach aims to provide deeper insights into the potential motivations and strategic calculus driving Russian actions...
* **Predictive Analysis Support:** While not a replacement for traditional intelligence gathering, this simulation can potentially...
* **Augmenting Intelligence:** This tool could augment existing intelligence analysis...

**Technology Stack:**

* **Language/Runtime:** TypeScript, Node.js
* **Web Framework:** Express.js
* **LLM Interaction Framework:** BAML (`@boundaryml/baml`)
* **LLM:** OpenAI GPT-4o
* **Vector Embeddings & Reranking:** Voyage AI (`voyageai` library, models: `voyage-01`, `voyage-3`, `rerank-2`)
* **Vector Database:** Supabase (PostgreSQL with pgvector implied)
* **Audio Transcription (Optional):** OpenAI Whisper
* **(Likely) Frontend:** HTML, CSS, JavaScript

*Limitations & Considerations:*

* Simulation, Not Reality: This is an AI interpretation based on available data, not a factual representation of Vladimir Putin's private thoughts.
* Data Bias: The output is inherently influenced by the biases present in the training data and the selected sources.
* Speculative Nature: Modeling "unfiltered thoughts" is inherently speculative.
* Ethical Sensitivity: Simulating a living world leader involved in significant global events requires careful consideration. This project is undertaken strictly for analytical exploration within the hackathon context.
* Hackathon Scope: This is a proof-of-concept demonstrating the approach, developed within a limited timeframe.

**Conclusion:**

This project demonstrates a RAG-based application of LLMs for geopolitical analysis. By attempting to model the inferred, unfiltered strategic thinking of a world leader, informed by relevant data retrieved in real-time, we aim to showcase how AI can contribute to a more nuanced understanding of international relations and potentially enhance predictive intelligence capabilities regarding the actions of states like the Russian Federation.
